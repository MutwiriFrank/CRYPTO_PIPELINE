Spark Executor Command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx2048M" "-Dspark.driver.blockManager.port=7080" "-Dspark.port.maxRetries=50" "-Dspark.driver.port=7078" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@airflow-scheduler:7078" "--executor-id" "0" "--hostname" "172.31.0.4" "--cores" "2" "--app-id" "app-20250421110147-0000" "--worker-url" "spark://Worker@172.31.0.4:33683" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/04/21 11:01:49 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 106@1bc2de7861bf
25/04/21 11:01:49 INFO SignalUtils: Registering signal handler for TERM
25/04/21 11:01:49 INFO SignalUtils: Registering signal handler for HUP
25/04/21 11:01:49 INFO SignalUtils: Registering signal handler for INT
25/04/21 11:01:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/04/21 11:01:50 INFO SecurityManager: Changing view acls to: spark,airflow
25/04/21 11:01:50 INFO SecurityManager: Changing modify acls to: spark,airflow
25/04/21 11:01:50 INFO SecurityManager: Changing view acls groups to: 
25/04/21 11:01:50 INFO SecurityManager: Changing modify acls groups to: 
25/04/21 11:01:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
25/04/21 11:01:50 INFO TransportClientFactory: Successfully created connection to airflow-scheduler/172.31.0.7:7078 after 111 ms (0 ms spent in bootstraps)
25/04/21 11:01:51 INFO SecurityManager: Changing view acls to: spark,airflow
25/04/21 11:01:51 INFO SecurityManager: Changing modify acls to: spark,airflow
25/04/21 11:01:51 INFO SecurityManager: Changing view acls groups to: 
25/04/21 11:01:51 INFO SecurityManager: Changing modify acls groups to: 
25/04/21 11:01:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark, airflow; groups with view permissions: EMPTY; users with modify permissions: spark, airflow; groups with modify permissions: EMPTY
25/04/21 11:01:51 INFO TransportClientFactory: Successfully created connection to airflow-scheduler/172.31.0.7:7078 after 5 ms (0 ms spent in bootstraps)
25/04/21 11:01:51 INFO DiskBlockManager: Created local directory at /opt/bitnami/spark/temp/spark-863e3c31-2ddc-4691-a6dc-fe25ac8e09de/executor-beb735c6-bb25-4238-a0ee-84d1a3390347/blockmgr-c7a5a9e3-58ef-4d9d-b551-8f8ce2abab15
25/04/21 11:01:51 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
25/04/21 11:01:51 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@airflow-scheduler:7078
25/04/21 11:01:51 INFO WorkerWatcher: Connecting to worker spark://Worker@172.31.0.4:33683
25/04/21 11:01:51 INFO ResourceUtils: ==============================================================
25/04/21 11:01:51 INFO ResourceUtils: No custom resources configured for spark.executor.
25/04/21 11:01:51 INFO ResourceUtils: ==============================================================
25/04/21 11:01:51 INFO TransportClientFactory: Successfully created connection to /172.31.0.4:33683 after 17 ms (0 ms spent in bootstraps)
25/04/21 11:01:51 INFO WorkerWatcher: Successfully connected to spark://Worker@172.31.0.4:33683
25/04/21 11:01:51 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
25/04/21 11:01:51 INFO Executor: Starting executor ID 0 on host 172.31.0.4
25/04/21 11:01:51 INFO Executor: OS info Linux, 5.15.49-linuxkit, amd64
25/04/21 11:01:51 INFO Executor: Java version 17.0.10
25/04/21 11:01:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33129.
25/04/21 11:01:51 INFO NettyBlockTransferService: Server created on 172.31.0.4:33129
25/04/21 11:01:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/04/21 11:01:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 172.31.0.4, 33129, None)
25/04/21 11:01:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 172.31.0.4, 33129, None)
25/04/21 11:01:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 172.31.0.4, 33129, None)
25/04/21 11:01:51 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/04/21 11:01:51 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@29d4bb1f for default.
25/04/21 11:01:51 INFO Executor: Fetching spark://airflow-scheduler:7078/jars/postgresql-jdbc.jar with timestamp 1745233306768
25/04/21 11:01:51 INFO TransportClientFactory: Successfully created connection to airflow-scheduler/172.31.0.7:7078 after 2 ms (0 ms spent in bootstraps)
25/04/21 11:01:51 INFO Utils: Fetching spark://airflow-scheduler:7078/jars/postgresql-jdbc.jar to /opt/bitnami/spark/temp/spark-863e3c31-2ddc-4691-a6dc-fe25ac8e09de/executor-beb735c6-bb25-4238-a0ee-84d1a3390347/spark-dfdb5a98-c69b-48d0-85eb-b5f2011c3f8a/fetchFileTemp17169314536917550140.tmp
25/04/21 11:01:52 INFO Utils: Copying /opt/bitnami/spark/temp/spark-863e3c31-2ddc-4691-a6dc-fe25ac8e09de/executor-beb735c6-bb25-4238-a0ee-84d1a3390347/spark-dfdb5a98-c69b-48d0-85eb-b5f2011c3f8a/791127181745233306768_cache to /opt/bitnami/spark/work/app-20250421110147-0000/0/./postgresql-jdbc.jar
25/04/21 11:01:52 INFO Executor: Adding file:/opt/bitnami/spark/work/app-20250421110147-0000/0/./postgresql-jdbc.jar to class loader default
25/04/21 11:01:53 INFO CoarseGrainedExecutorBackend: Got assigned task 0
25/04/21 11:01:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/04/21 11:01:53 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
25/04/21 11:01:54 INFO TransportClientFactory: Successfully created connection to airflow-scheduler/172.31.0.7:7080 after 1 ms (0 ms spent in bootstraps)
25/04/21 11:01:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 1048.8 MiB)
25/04/21 11:01:54 INFO TorrentBroadcast: Reading broadcast variable 0 took 136 ms
25/04/21 11:01:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.0 KiB, free 1048.8 MiB)
25/04/21 11:01:54 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.io.InvalidClassException: org.apache.spark.rdd.RDD; local class incompatible: stream classdesc serialVersionUID = 823754013007382808, local class serialVersionUID = 3516924559342767982
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
25/04/21 11:01:54 INFO CoarseGrainedExecutorBackend: Got assigned task 1
25/04/21 11:01:54 INFO Executor: Running task 0.1 in stage 0.0 (TID 1)
25/04/21 11:01:54 ERROR Executor: Exception in task 0.1 in stage 0.0 (TID 1)
java.io.InvalidClassException: org.apache.spark.rdd.RDD; local class incompatible: stream classdesc serialVersionUID = 823754013007382808, local class serialVersionUID = 3516924559342767982
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
25/04/21 11:01:54 INFO CoarseGrainedExecutorBackend: Got assigned task 2
25/04/21 11:01:54 INFO Executor: Running task 0.2 in stage 0.0 (TID 2)
25/04/21 11:01:54 ERROR Executor: Exception in task 0.2 in stage 0.0 (TID 2)
java.io.InvalidClassException: org.apache.spark.rdd.RDD; local class incompatible: stream classdesc serialVersionUID = 823754013007382808, local class serialVersionUID = 3516924559342767982
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
25/04/21 11:01:54 INFO CoarseGrainedExecutorBackend: Got assigned task 3
25/04/21 11:01:54 INFO Executor: Running task 0.3 in stage 0.0 (TID 3)
25/04/21 11:01:54 ERROR Executor: Exception in task 0.3 in stage 0.0 (TID 3)
java.io.InvalidClassException: org.apache.spark.rdd.RDD; local class incompatible: stream classdesc serialVersionUID = 823754013007382808, local class serialVersionUID = 3516924559342767982
	at java.base/java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:597)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:2051)
	at java.base/java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1898)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2224)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream$FieldValues.<init>(ObjectInputStream.java:2606)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2457)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2257)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1733)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:509)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:467)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:87)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:129)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:90)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
25/04/21 11:01:54 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
25/04/21 11:01:54 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
